{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra.\n",
    "\n",
    "Se tiene acceso a los datos de comportamiento de los suscriptores que ya se han cambiado a los planes nuevos (del proyecto del sprint de Análisis estadístico de datos). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `/datasets/users_behavior.csv '` contiene los siguientes datos:\n",
    "  \n",
    "   -`сalls:` número de llamadas\n",
    "     \n",
    "   -`minutes` — duración total de la llamada en minutos\n",
    "  \n",
    "   -`messages` — número de mensajes de texto\n",
    "  \n",
    "   -`mb_used` — Tráfico de Internet utilizado en MB\n",
    "  \n",
    "   -`is_ultra` — plan para el mes actual (Ultra - 1, Smart - 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/users_behavior.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n",
      "\n",
      "El dataset tiene 0 duplicados\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "nulos = data.isnull().sum()\n",
    "print(nulos)\n",
    "print()\n",
    "print('El dataset tiene', data.duplicated().sum(),'duplicados')\n",
    "print()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['messages'] = data['messages'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos del conjunto de datos se encuentran completos, correctamente estructurados y no requirieron modificaciones. No obstante, la columna 'messages' fue convertida al tipo de dato 'int64' como buena práctica, considerando que no existe la posibilidad de que se generen valores decimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2229\n",
       "1     985\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = data['is_ultra'].value_counts()\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos muestra un desbalance moderado, con una proporción de 30,64% para la clase 1 y 69,35% para la clase 0, lo cual podría afectar el rendimiento de algunos clasificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se separa el dataset en una relación 3:1, es decir, el 75% de los datos se utilizan para el entrenamiento del modelo (df_train) y el 25% restante para validación o prueba (df_valid).Como variable objetivo (target) se selecciona la columna 'is_ultra', y como características (features) se utilizan las columnas restantes: 'call', 'minutes', 'messages' y 'mb_used'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separción  de los datos de entrenamiento y validación\n",
    "df_train, df_valid = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Declaración de las variables de las caracteristicas  y los objeticos\n",
    "#Entrenamiento\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "#Validación\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2410, 4)\n",
      "(2410,)\n",
      "(804, 4)\n",
      "(804,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la prueba de cordura, se busca verificar si el modelo realmente está aprendiendo algo significativo. Dado que el conjunto de datos presenta un desbalance aproximado del 70%-30%, un modelo que simplemente prediga siempre la clase mayoritaria (clase 0) alcanzaría una accuracy del 70% sin aportar valor real.\n",
    "Por esta razón, esta prueba es fundamental para determinar si el modelo está aprendiendo patrones útiles o si solo está aprovechando el desbalance de clases.\n",
    "Para ello, se calcula un dummy accuracy, que corresponde a la proporción de la clase más frecuente en los datos, y se compara con la accuracy del modelo. Si el modelo no supera esta métrica, se considera que no ha aprendido nada mejor que una predicción trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test para prueba de cordura\n",
    "dummy_accuracy= target_valid.value_counts(normalize=True).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(random_state=42,solver='liblinear')\n",
    "log_reg.fit(features_train,target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72388\n",
      "precisión:0.86957\n",
      "Recall:0.08368\n",
      "F1_score:0.15267\n",
      "ROC AUC clase 1: 0.59199\n"
     ]
    }
   ],
   "source": [
    "lr_prediction = log_reg.predict(features_valid)\n",
    "prefiction_lr_1= log_reg.predict_proba(features_valid)[:,1]\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(target_valid, lr_prediction):.5f}')\n",
    "print(f'precisión:{precision_score(target_valid, lr_prediction):.5f}')\n",
    "print(f'Recall:{recall_score(target_valid, lr_prediction):.5f}')\n",
    "print(f'F1_score:{f1_score(target_valid, lr_prediction):.5f}')\n",
    "print(f'ROC AUC clase 1: {roc_auc_score(target_valid, prefiction_lr_1 ):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo pasa la prueba de cordura.\n"
     ]
    }
   ],
   "source": [
    "# Prueba de cordura\n",
    "lr_acurracy = accuracy_score(target_valid, lr_prediction)\n",
    "if lr_acurracy <= dummy_accuracy:\n",
    "    print(\"¡Tu modelo no supera a un clasificador tonto!\")\n",
    "else:\n",
    "    print(\"El modelo pasa la prueba de cordura.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras varias modificaciones a los hiperparámetros, no se logró que el modelo de regresión logística alcanzara el umbral de exactitud 0.75. Sin embargo, es importante destacar que el modelo presenta una precisión alta (0.86), lo que indica que, cuando predice un positivo, suele acertar.No obstante, el recall es muy bajo, lo que revela que el modelo casi no logra detectar verdaderos positivos, es decir, deja pasar la mayoría de los casos relevantes. Esta combinación de alta precisión y bajo recall resulta en un F1-score bajo (0.15), lo cual refleja un rendimiento general deficiente para tareas donde es crítico identificar todos los casos positivos. Adicionalmente, el valor del Área bajo la curva ROC (AUC-ROC) es de 0.59, lo que sugiere que el modelo apenas supera el rendimiento esperado por azar (0.5) y no logra discriminar adecuadamente entre clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del mejor modelo en el conjunto de validación (n_estimators = 41): 0.8283582089552238\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "\n",
    "for est in range(1, 100,5): \n",
    "    model_rf = RandomForestClassifier(random_state=42, n_estimators=est) \n",
    "    model_rf.fit(features_train, target_train) \n",
    "    score = model_rf.score(features_valid,target_valid) \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "print(\"La exactitud del mejor modelo en el conjunto de validación (n_estimators = {}): {}\".format(best_est, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82960\n",
      "precisión:0.78652\n",
      "Recall:0.58577\n",
      "F1_score:0.67146\n",
      "ROC AUC clase 1: 0.80021\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42, n_estimators=42,criterion='gini')\n",
    "rf.fit(features_train,target_train)\n",
    "\n",
    "prediction_rf = rf.predict(features_valid)\n",
    "prediction_rf_1 = rf.predict_proba(features_valid)[:,1]\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(target_valid, prediction_rf):.5f}')\n",
    "print(f'precisión:{precision_score(target_valid, prediction_rf):.5f}')\n",
    "print(f'Recall:{recall_score(target_valid, prediction_rf):.5f}')\n",
    "print(f'F1_score:{f1_score(target_valid, prediction_rf):.5f}')\n",
    "print(f'ROC AUC clase 1: {roc_auc_score(target_valid, prediction_rf_1):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo pasa la prueba de cordura.\n"
     ]
    }
   ],
   "source": [
    "# Prueba de cordura\n",
    "rf_acurracy = accuracy_score(target_valid, prediction_rf)\n",
    "if lr_acurracy <= dummy_accuracy:\n",
    "    print(\"¡Tu modelo no supera a un clasificador tonto!\")\n",
    "else:\n",
    "    print(\"El modelo pasa la prueba de cordura.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo evaluado supera el umbral de exactitud establecido en 0.75, alcanzando un accuracy de 0.83, lo cual refleja un buen rendimiento general. No obstante, debido al desbalance presente en el conjunto de datos, la exactitud por sí sola no resulta suficiente para evaluar adecuadamente su desempeño. La precisión de 0.78652 indica que, cuando el modelo predice la clase positiva (1), suele acertar con alta frecuencia. Por otro lado, el recall de 0.58577 sugiere que el modelo es capaz de identificar una proporción moderada de los casos positivos reales, aunque deja pasar una cantidad considerable. En consecuencia, el F1-score de 0.67146, que representa un equilibrio entre precisión y recall, es aceptable.Finalmente, el ROC AUC de 0.80 para la clase 1 demuestra que el modelo posee una buena capacidad de discriminación entre clases, incluso en contextos de desbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78980\n",
      "precisión:0.73333\n",
      "Recall:0.46025\n",
      "F1_score:0.56555\n",
      "ROC AUC clase 1: 0.74533\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')\n",
    "knn.fit(features_train,target_train)\n",
    "\n",
    "prediction_knn = knn.predict(features_valid)\n",
    "prediction_knn_1 = knn.predict_proba(features_valid)[:,1]\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(target_valid, prediction_knn):.5f}')\n",
    "print(f'precisión:{precision_score(target_valid, prediction_knn):.5f}')\n",
    "print(f'Recall:{recall_score(target_valid, prediction_knn):.5f}')\n",
    "print(f'F1_score:{f1_score(target_valid, prediction_knn):.5f}')\n",
    "print(f'ROC AUC clase 1: {roc_auc_score(target_valid, prediction_knn_1 ):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo pasa la prueba de cordura.\n"
     ]
    }
   ],
   "source": [
    "# Prueba de cordura\n",
    "knn_acurracy = accuracy_score(target_valid, prediction_knn)\n",
    "if knn_acurracy <= dummy_accuracy:\n",
    "    print(\"El modelo no supera a un clasificador tonto\")\n",
    "else:\n",
    "    print(\"El modelo pasa la prueba de cordura.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo K-Nearest Neighbors alcanzó una exactitud de 0.78980, superando ligeramente el umbral establecido de 0.75, lo cual indica un rendimiento general aceptable. Sin embargo, al considerar el desbalance del conjunto de datos, es necesario analizar métricas adicionales. La precisión de 0.73333 revela que, cuando el modelo predice la clase positiva (1), en la mayoría de los casos acierta. No obstante, el recall de 0.46025 indica que el modelo logra identificar menos de la mitad de los positivos reales, lo que sugiere una capacidad limitada para recuperar todos los casos relevantes. Como resultado, el F1-score de 0.56555, que equilibra precisión y recall, refleja un desempeño moderado que podría mejorarse en tareas donde la detección de la clase positiva sea crítica. Por último, el ROC AUC de 0.74533 para la clase 1 muestra una capacidad discriminativa aceptable, aunque inferior a la de otros modelos evaluados, lo que sugiere que el KNN tiene un rendimiento adecuado, pero aún podría optimizarse frente al desbalance existente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árbol de decisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73756\n",
      "precisión:0.55785\n",
      "Recall:0.56485\n",
      "F1_score:0.56133\n",
      "ROC AUC clase 1: 0.68774\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=42, max_depth=42)\n",
    "dtree.fit(features_train,target_train)\n",
    "\n",
    "prediction_dtree = dtree.predict(features_valid)\n",
    "prediction_dtree_1 = dtree.predict_proba(features_valid)[:,1]\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(target_valid, prediction_dtree):.5f}')\n",
    "print(f'precisión:{precision_score(target_valid, prediction_dtree):.5f}')\n",
    "print(f'Recall:{recall_score(target_valid, prediction_dtree):.5f}')\n",
    "print(f'F1_score:{f1_score(target_valid, prediction_dtree):.5f}')\n",
    "print(f'ROC AUC clase 1: {roc_auc_score(target_valid, prediction_dtree_1 ):.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba de cordura\n",
    "dtree_acurracy = accuracy_score(target_valid, prediction_dtree)\n",
    "if dtree_acurracy <= dummy_accuracy:\n",
    "    print(\"El modelo no supera a un clasificador tonto\")\n",
    "else:\n",
    "    print(\"El modelo pasa la prueba de cordura.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo Decision Tree Classifier obtuvo una exactitud de 0.73756, quedando ligeramente por debajo del umbral de referencia de 0.75. Aunque esta métrica sugiere un desempeño general cercano al esperado, en contextos con desbalance de clases (como en este caso), la exactitud no es suficiente para evaluar la calidad del modelo. La precisión de 0.55785 indica que, cuando el modelo predice la clase positiva (1), algo más de la mitad de esas predicciones son correctas. Por otro lado, el recall de 0.56485 muestra que el modelo es capaz de identificar alrededor del 56% de los casos positivos reales, lo cual representa una capacidad de recuperación moderada. El F1-score de 0.56133, que armoniza precisión y recall, refuerza la idea de que el modelo tiene un rendimiento aceptable, aunque sin destacar significativamente en ninguno de los dos aspectos y por ultimo el ROC AUC de 0.68 para la clase 1, que evidencia capacidad media para discriminar entre clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82338\n",
      "precisión:0.78363\n",
      "Recall:0.56067\n",
      "F1_score:0.65366\n",
      "ROC AUC clase 1: 0.80732\n"
     ]
    }
   ],
   "source": [
    "xbg = XGBClassifier(    eval_metric='auc', use_label_encoder=False,random_state=42)\n",
    "xbg.fit(features_train,target_train)\n",
    "\n",
    "prediction_xbg = xbg.predict(features_valid)\n",
    "prediction_xbg_1 = xbg.predict_proba(features_valid)[:,1]\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(target_valid, prediction_xbg):.5f}')\n",
    "print(f'precisión:{precision_score(target_valid, prediction_xbg):.5f}')\n",
    "print(f'Recall:{recall_score(target_valid, prediction_xbg):.5f}')\n",
    "print(f'F1_score:{f1_score(target_valid, prediction_xbg):.5f}')\n",
    "print(f'ROC AUC clase 1: {roc_auc_score(target_valid, prediction_xbg_1 ):.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba de cordura\n",
    "xbg_acurracy = accuracy_score(target_valid, prediction_xbg)\n",
    "if xbg_acurracy <= dummy_accuracy:\n",
    "    print(\"El modelo no supera a un clasificador tonto\")\n",
    "else:\n",
    "    print(\"El modelo pasa la prueba de cordura.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo XGBoost Classifier muestra un rendimiento general sólido, alcanzando una exactitud de 0.82338, superando el umbral de 0.75 establecido como referencia. Este valor sugiere que el modelo clasifica correctamente una proporción alta de los datos. La precisión de 0.78363 indica que, cuando predice la clase positiva (1), acierta en una gran mayoría de los casos, lo cual es valioso en contextos donde los falsos positivos deben minimizarse. El recall de 0.56067, aunque moderado, refleja que el modelo logra identificar un número razonable de los verdaderos positivos, aunque aún hay margen de mejora. El F1-score de 0.65366, al combinar precisión y recall, evidencia un equilibrio decente entre ambas métricas. Finalmente, el ROC AUC de 0.80732 para la clase 1 destaca como uno de los puntos más fuertes del modelo, demostrando una buena capacidad para discriminar entre clases en un conjunto de datos con desbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras el desarrollo, ajuste y evaluación de los diferentes modelos de clasificación, se identificaron como más adecuados el **RandomForestClassifier** y el **XGBoostClassifier**, los cuales demostraron una mayor capacidad para desempeñar la tarea de forma eficiente. Aunque todos los modelos fueron capaces de manejar razonablemente bien el desbalance moderado del conjunto de datos logrando un ROC AUC mayor a 0.80 para la clase 1, **solo estos dos modelos superaron el umbral de exactitud de 0.75** y presentaron una mejor relación entre precisión, recall y F1-score, lo que indica un balance más efectivo en la predicción de ambas clases.\n",
    "\n",
    "Se intentó mitigar el desbalance aplicando técnicas como class_weight='balanced' en modelos lineales y scale_pos_weight=700/300 en modelos basados en árboles, pero no se obtuvieron mejoras significativas en el rendimiento. También se consideró la aplicación de SMOTE (Synthetic Minority Over-sampling Technique) como estrategia de sobremuestreo para mejorar la detección de la clase minoritaria, pero las restricciones del entorno virtual de la plataforma impidieron su implementación. A pesar de estas limitaciones, el desempeño alcanzado por los modelos seleccionados es satisfactorio para tareas de clasificación con conjuntos de datos moderadamente desbalanceados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
